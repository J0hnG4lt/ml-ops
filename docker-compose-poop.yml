version: "3.4"
x-airflow-common:
  &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.0.1}
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  depends_on:
    redis:
      condition: service_healthy
    postgres:
      condition: service_healthy

services:
    nginx:
        container_name: nginx
        build: ./nginx
        restart: always
        depends_on: 
            - python-model-service1
            - python-model-service2
        ports:
        - "80:80"
        - "443:443"
        # volumes: 
        #     - ./nginx.conf:/etc/nginx/nginx.conf
    
    python-model-service1:
        restart: always
        container_name: python-service-1
        depends_on:
            - rabbitmq
        build:
            context: ./python-model-service-1
            dockerfile: Dockerfile
        ports:
            - "8000:8000"
        volumes:
            - ./python-model-service-1:/python-model-service-1
    
    python-model-service2:
        restart: always
        container_name: python-service-2
        depends_on:
            - rabbitmq
        build: 
            context: ./python-model-service-2
            dockerfile: Dockerfile
        ports:
            - "8001:8001"
        volumes:
            - ./python-model-service-2:/python-model-service-2

    postgres:
        container_name: postgres
        build: ./postgres
        env_file:
            - ./postgres/postgres.env
        ports:
            - 5432:5432
        volumes:
                - ./volumes/postgres/data:/var/lib/postgresql/data
                # - postgres-db-volume:/var/lib/postgresql/data
        healthcheck:
            test: ["CMD", "pg_isready", "-U", "airflow"]
            interval: 5s
            retries: 5
        restart: always

    # postgres:
    #     image: postgres:13
    #     environment:
    #         POSTGRES_USER: airflow
    #         POSTGRES_PASSWORD: airflow
    #         POSTGRES_DB: airflow
    #     volumes:
    #         - postgres-db-volume:/var/lib/postgresql/data
    #     healthcheck:
    #         test: ["CMD", "pg_isready", "-U", "airflow"]
    #         interval: 5s
    #         retries: 5
    #     restart: always


    rabbitmq:
        restart: always
        container_name: rabbitmq
        image: rabbitmq:3-management-alpine
        volumes:
            - ./rabbitmq/etc/definitions.json:/etc/rabbitmq/definitions.json
        # environment:
        #     RABBITMQ_ERLANG_COOKIE: "SWQOKODSQALRPCLNMEQG"
        #     RABBITMQ_DEFAULT_USER: "guest"
        #     RABBITMQ_DEFAULT_PASS: "guest"
        #     RABBITMQ_DEFAULT_VHOST: "/"
        ports:
            - "15672:15672"
            - "5672:5672"

    rabbitmq-workers:
        restart: always
        container_name: rabbitmq-workers
        build: ./workers
        depends_on:
            - rabbitmq

    mlflow:
        container_name: mlflow-server
        depends_on:
            - postgres
        build: ./mlflow
        restart: always
        image: mlflow_server 
        ports: 
            - "5000:5000"
        command: 
            mlflow server --backend-store-uri postgresql://mlflow:metadata@postgres/mlflowdb --default-artifact-root s3://shiptmlflowbucket/mlflow --host 0.0.0.0 -p 5000
    
    influxdb:
        container_name: influxdb
        # image: "influxdb:latest"
        build: ./influxdb
        restart: always
        ports:
            - 8086:8086
            - 8083:8083
            - 2003:2003
        env_file:
            - ./influxdb/influxdb.env
        # volumes:
        #     - ./volumes/influxdb/data:/var/lib/influxdb
        #     - ./influxdb/backups/influxdb/db:/var/lib/influxdb/backup

    chronograf:
        restart: always
        container_name: chronograf
        depends_on:
            - influxdb
        image: chronograf:1.8.4-alpine
        user: "0"
        ports:
            - 8888:8888
        env_file:
            - ./chronograf/chronograf.env
        volumes:
            - ./volumes/chronograf/data:/var/lib/chronograf
            - ./volumes/chronograf/log:/var/log/chronograf

    grafana:
        container_name: grafana
        depends_on:
            - influxdb
        image: grafana/grafana:6.3.6
        restart: always
        user: "0"
        ports:
            - 3000:3000
        env_file:
            - ./grafana/grafana.env
        volumes:
            - ./volumes/grafana/data:/var/lib/grafana
            - ./volumes/grafana/log:/var/log/grafana
    
    redis:
        image: redis:latest
        ports:
            - 6379:6379
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 5s
            timeout: 30s
            retries: 50
        restart: always
        command: redis-server --requirepass redispass

    # telegraf:
    #     container_name: telegraf
    #     restart: always
    #     build: ./telegraf
    #     depends_on: 
    #         - influxdb

# ORIGINAL AIRFLOW CONFIG
    airflow-webserver:
        restart: always
        container_name: airflow-webserver
        image: puckel/docker-airflow:1.10.9
        depends_on:
            - postgres
            - redis
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        # volumes:
        #     - ./airflow/dags:/usr/local/airflow/dags
        #     Uncomment to include custom plugins
        #     - ./plugins:/usr/local/airflow/plugins
        ports:
            - "8080:8080"
        command: webserver
        healthcheck:
            test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
            interval: 30s
            timeout: 30s
            retries: 3

    airflow-flower:
        container_name: airflow-flower
        image: puckel/docker-airflow:1.10.9
        restart: always
        depends_on:
            - redis
        environment:
            - EXECUTOR=Celery
            - REDIS_PASSWORD=redispass
        ports:
            - "5555:5555"
        command: flower

    airflow-scheduler:
        container_name: airlfow-scheduler
        image: puckel/docker-airflow:1.10.9
        restart: always
        depends_on:
            - airflow-webserver
        # volumes:
        #     - ./airflow/dags:/usr/local/airflow/dags
        # Uncomment to include custom plugins
        # - ./plugins:/usr/local/airflow/plugins
        environment:
            - LOAD_EX=n
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        command: scheduler

    airflow-worker:
        container_name: airflow-worker
        image: puckel/docker-airflow:1.10.9
        restart: always
        depends_on:
            - airflow-scheduler
        # volumes:
        #     - ./airflow/dags:/usr/local/airflow/dags
        #     Uncomment to include custom plugins
        #     - ./plugins:/usr/local/airflow/plugins
        environment:
            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
            - EXECUTOR=Celery
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=airflow
            - POSTGRES_DB=airflow
            - REDIS_PASSWORD=redispass
        command: worker

    # redis:
    #     container_name: redis
    #     image: redis
    #     command: redis-server --requirepass redispass

    # portainer:
    #     container_name: portainer
    #     image: portainer/portainer
    #     restart: always
    #     ports:
    #         - "9000:9000"
    #     volumes:
    #         - /var/run/docker.sock:/var/run/docker.sock
    #     #     - ./volumes/portainer/data:/data


volumes:
  postgres-db-volume: